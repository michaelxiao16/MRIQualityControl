{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv3d(1, 6, kernel_size=(8, 8, 8), stride=(2, 2, 2))\n",
      "  (conv2): Conv3d(6, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "  (fc1): Linear(in_features=176400, out_features=5, bias=True)\n",
      "  (fc2): Linear(in_features=5, out_features=20, bias=True)\n",
      "  (fc3): Linear(in_features=20, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "sys.path.append(\"/usr/local/lib/python3.5/dist-packages/\")\n",
    "import nibabel as nib\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
    "        # kernel\n",
    "        \n",
    "        self.conv1 = nn.Conv3d(1, 6, 8, stride=2)\n",
    "        self.conv2 = nn.Conv3d(6,16,3)\n",
    "        \n",
    "        #self.maxpool1 = F.max_pool3d(2)\n",
    "        #self.relu1 = F.relu()\n",
    "        \n",
    "        #self.maxpool2 = F.max_pool3d(2)\n",
    "        \n",
    "        \n",
    "        #self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        #self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 21 * 25 * 21, 5)  # 6*6 from image dimension\n",
    "        self.fc2 = nn.Linear(5, 20)\n",
    "        self.fc3 = nn.Linear(20, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        #x = self.conv1(x)\n",
    "        #x = self.relu1(x)\n",
    "        #x = self.max_pool3d1(x)\n",
    "        \n",
    "        #x = self.conv2(x)\n",
    "        #x = self.relu1(x)\n",
    "        #x = self.max_pool3d2(x)\n",
    "#         x = self.conv1(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = F.max_pool3d(x)\n",
    "        x = F.max_pool3d(F.relu(self.conv1(x)), (2, 2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool3d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "net.cuda()\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.005)\n",
    "criterion = nn.BCELoss()\n",
    "criterion.cuda()\n",
    "\n",
    "\n",
    "batch_size = 20\n",
    "D, R, C = (182, 218,182)\n",
    "x = torch.zeros((batch_size,1,D,R,C))\n",
    "y = torch.zeros(batch_size)\n",
    "offset = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1500 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(70., device='cuda:0')\n",
      "tensor(62.5000, device='cuda:0')\n",
      "tensor(61.6667, device='cuda:0')\n",
      "tensor(62.5000, device='cuda:0')\n",
      "tensor(62., device='cuda:0')\n",
      "tensor(63.3333, device='cuda:0')\n",
      "tensor(64.2857, device='cuda:0')\n",
      "tensor(66.2500, device='cuda:0')\n",
      "tensor(68.8889, device='cuda:0')\n",
      "tensor(68.5000, device='cuda:0')\n",
      "tensor(69.0909, device='cuda:0')\n",
      "tensor(67.5000, device='cuda:0')\n",
      "tensor(67.3077, device='cuda:0')\n",
      "tensor(67.8571, device='cuda:0')\n",
      "tensor(69.3333, device='cuda:0')\n",
      "tensor(68.4375, device='cuda:0')\n",
      "tensor(68.2353, device='cuda:0')\n",
      "tensor(68.0556, device='cuda:0')\n",
      "tensor(69.2105, device='cuda:0')\n",
      "tensor(69.5000, device='cuda:0')\n",
      "tensor(69.2857, device='cuda:0')\n",
      "tensor(70.2273, device='cuda:0')\n",
      "tensor(71.3043, device='cuda:0')\n",
      "tensor(71.4583, device='cuda:0')\n",
      "tensor(71.4000, device='cuda:0')\n",
      "tensor(71.5385, device='cuda:0')\n",
      "tensor(71.6667, device='cuda:0')\n",
      "tensor(71.7857, device='cuda:0')\n",
      "tensor(71.0345, device='cuda:0')\n",
      "tensor(71., device='cuda:0')\n",
      "tensor(70.6452, device='cuda:0')\n",
      "tensor(70.6250, device='cuda:0')\n",
      "tensor(70.4545, device='cuda:0')\n",
      "tensor(70.2941, device='cuda:0')\n",
      "tensor(70.4286, device='cuda:0')\n",
      "tensor(70.4167, device='cuda:0')\n",
      "tensor(70.4054, device='cuda:0')\n",
      "tensor(70.5263, device='cuda:0')\n",
      "tensor(70.5128, device='cuda:0')\n",
      "tensor(70.1250, device='cuda:0')\n",
      "tensor(69.8781, device='cuda:0')\n",
      "tensor(69.5238, device='cuda:0')\n",
      "tensor(69.0698, device='cuda:0')\n",
      "tensor(68.7500, device='cuda:0')\n",
      "tensor(68.8889, device='cuda:0')\n",
      "tensor(68.5870, device='cuda:0')\n",
      "tensor(68.5106, device='cuda:0')\n",
      "tensor(68.3333, device='cuda:0')\n",
      "tensor(68.4694, device='cuda:0')\n",
      "tensor(68.3000, device='cuda:0')\n",
      "tensor(68.3333, device='cuda:0')\n",
      "tensor(68.3654, device='cuda:0')\n",
      "tensor(68.3962, device='cuda:0')\n",
      "tensor(68.4259, device='cuda:0')\n",
      "tensor(68.3636, device='cuda:0')\n",
      "tensor(68.6607, device='cuda:0')\n",
      "tensor(68.3333, device='cuda:0')\n",
      "tensor(68.2759, device='cuda:0')\n",
      "tensor(68.1356, device='cuda:0')\n",
      "tensor(68.2500, device='cuda:0')\n",
      "tensor(68.5246, device='cuda:0')\n",
      "tensor(68.6290, device='cuda:0')\n",
      "tensor(68.8889, device='cuda:0')\n",
      "tensor(69.0625, device='cuda:0')\n",
      "tensor(69.1538, device='cuda:0')\n",
      "tensor(69.0909, device='cuda:0')\n",
      "tensor(69.0299, device='cuda:0')\n",
      "tensor(68.8971, device='cuda:0')\n",
      "tensor(69.1304, device='cuda:0')\n",
      "tensor(69.2143, device='cuda:0')\n",
      "tensor(69.4366, device='cuda:0')\n",
      "tensor(69.4444, device='cuda:0')\n",
      "tensor(69.6575, device='cuda:0')\n",
      "tensor(69.7973, device='cuda:0')\n",
      "tensor(69.7333, device='cuda:0')\n",
      "tensor(69.8684, device='cuda:0')\n",
      "tensor(69.8701, device='cuda:0')\n",
      "tensor(70.0641, device='cuda:0')\n",
      "tensor(69.9367, device='cuda:0')\n",
      "tensor(69.6875, device='cuda:0')\n",
      "tensor(69.8148, device='cuda:0')\n",
      "tensor(69.6951, device='cuda:0')\n",
      "tensor(69.8193, device='cuda:0')\n",
      "tensor(69.8810, device='cuda:0')\n",
      "tensor(70.1176, device='cuda:0')\n",
      "tensor(70.2326, device='cuda:0')\n",
      "tensor(70.2874, device='cuda:0')\n",
      "tensor(70.2841, device='cuda:0')\n",
      "tensor(70.3933, device='cuda:0')\n",
      "tensor(70.3333, device='cuda:0')\n",
      "tensor(70.3297, device='cuda:0')\n",
      "tensor(70.3261, device='cuda:0')\n",
      "tensor(70.3763, device='cuda:0')\n",
      "tensor(70.4255, device='cuda:0')\n",
      "tensor(70.3684, device='cuda:0')\n",
      "tensor(70.3125, device='cuda:0')\n",
      "tensor(70.0516, device='cuda:0')\n",
      "tensor(69.8469, device='cuda:0')\n",
      "tensor(69.7980, device='cuda:0')\n",
      "tensor(69.6500, device='cuda:0')\n",
      "tensor(69.6535, device='cuda:0')\n",
      "tensor(69.7549, device='cuda:0')\n",
      "tensor(69.7573, device='cuda:0')\n",
      "tensor(69.8077, device='cuda:0')\n",
      "tensor(69.7143, device='cuda:0')\n",
      "tensor(69.5283, device='cuda:0')\n",
      "tensor(69.6262, device='cuda:0')\n",
      "tensor(69.6759, device='cuda:0')\n",
      "tensor(69.8165, device='cuda:0')\n",
      "tensor(69.9091, device='cuda:0')\n",
      "tensor(69.9550, device='cuda:0')\n",
      "tensor(69.9107, device='cuda:0')\n",
      "tensor(69.8673, device='cuda:0')\n",
      "tensor(69.8246, device='cuda:0')\n",
      "tensor(69.8261, device='cuda:0')\n",
      "tensor(69.8707, device='cuda:0')\n",
      "tensor(69.9145, device='cuda:0')\n",
      "tensor(69.9576, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "    \n",
    "df = np.genfromtxt(\"preprocessing/encoded_track2_labels_v2.csv\",delimiter=',')\n",
    "x_loc = df[1:,0]\n",
    "y_loc = df[1:,1]\n",
    "\n",
    "\n",
    "\n",
    "#df = np.genfromtxt(\"preprocessing/encoded_track2_labels.csv\",delimiter=',')\n",
    "#x_loc = df[1:,2]\n",
    "#y_loc = df[1:,3]\n",
    "\n",
    "\n",
    "epochs = 1500\n",
    "# in your training loop:\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    for i in range(150):\n",
    "        for j in range(batch_size):\n",
    "            loc = x_loc[j+offset]\n",
    "            example_filename = \"../brainhack/Sub-\" + str(int(loc)) + \".nii.gz\"\n",
    "            img = nib.load(example_filename)\n",
    "            data = img.get_fdata()\n",
    "            x[j,0,:,:,:] = torch.from_numpy(data).float()\n",
    "            y[j] = y_loc[j+offset]\n",
    "        offset = j+offset\n",
    "        input = x/x.max()\n",
    "        \n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()   # zero the gradient buffers\n",
    "        input = input.cuda()\n",
    "        y = y.cuda()\n",
    "        output = net(input)\n",
    "        loss = criterion(output.view(batch_size), y.view(batch_size))\n",
    "        loss.backward()\n",
    "        optimizer.step()    # Does the update\n",
    "        correct += ((output > 0.5).view(-1)*(y>0.5).view(-1)).sum()\n",
    "        total += batch_size\n",
    "        print(correct.float()*100/total)\n",
    "    \n",
    "    # save model\n",
    "    if epoch % 10 == 0:\n",
    "        torch.save(net,'cnn_epoch_'+str(epoch)+'.pt')\n",
    "#         print(loss)\n",
    "#         print(output)\n",
    "#         print(y)\n",
    "#         print(input.sum())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13, device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " ((output > 0.5).view(-1)*(y>0.5).view(-1)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo -H pip3 install nibabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
