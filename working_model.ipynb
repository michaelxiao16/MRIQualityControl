{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nibabel\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/01/13/392132019093ddb7bc997f7f9843d406dc3302a27f01827d2fd028e03c50/nibabel-2.5.1-py3-none-any.whl (3.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.3MB 13.0MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.3 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from nibabel) (1.11.0)\n",
      "Requirement already satisfied: numpy>=1.8 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from nibabel) (1.15.4)\n",
      "\u001b[31mfastai 1.0.58 requires nvidia-ml-py3, which is not installed.\u001b[0m\n",
      "Installing collected packages: nibabel\n",
      "Successfully installed nibabel-2.5.1\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install nibabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/font_manager.py:232: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  'Matplotlib is building the font cache using fc-list. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv3d(1, 6, kernel_size=(8, 8, 8), stride=(2, 2, 2))\n",
      "  (conv2): Conv3d(6, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "  (fc1): Linear(in_features=176400, out_features=5, bias=True)\n",
      "  (fc2): Linear(in_features=5, out_features=20, bias=True)\n",
      "  (fc3): Linear(in_features=20, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "sys.path.append(\"/usr/local/lib/python3.5/dist-packages/\")\n",
    "import nibabel as nib\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
    "        # kernel\n",
    "        \n",
    "        self.conv1 = nn.Conv3d(1, 6, 8, stride=2)\n",
    "        self.conv2 = nn.Conv3d(6,16,3)\n",
    "        \n",
    "        #self.maxpool1 = F.max_pool3d(2)\n",
    "        #self.relu1 = F.relu()\n",
    "        \n",
    "        #self.maxpool2 = F.max_pool3d(2)\n",
    "        \n",
    "        \n",
    "        #self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        #self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 21 * 25 * 21, 5)  # 6*6 from image dimension\n",
    "        self.fc2 = nn.Linear(5, 20)\n",
    "        self.fc3 = nn.Linear(20, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        #x = self.conv1(x)\n",
    "        #x = self.relu1(x)\n",
    "        #x = self.max_pool3d1(x)\n",
    "        \n",
    "        #x = self.conv2(x)\n",
    "        #x = self.relu1(x)\n",
    "        #x = self.max_pool3d2(x)\n",
    "#         x = self.conv1(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = F.max_pool3d(x)\n",
    "        x = F.max_pool3d(F.relu(self.conv1(x)), (2, 2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool3d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "net.cuda()\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.005)\n",
    "criterion = nn.BCELoss()\n",
    "criterion.cuda()\n",
    "\n",
    "\n",
    "batch_size = 20\n",
    "D, R, C = (182, 218,182)\n",
    "x = torch.zeros((batch_size,1,D,R,C))\n",
    "y = torch.zeros(batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(70., device='cuda:0')\n",
      "tensor(62.5000, device='cuda:0')\n",
      "tensor(61.6667, device='cuda:0')\n",
      "tensor(62.5000, device='cuda:0')\n",
      "tensor(62., device='cuda:0')\n",
      "tensor(63.3333, device='cuda:0')\n",
      "tensor(64.2857, device='cuda:0')\n",
      "tensor(66.2500, device='cuda:0')\n",
      "tensor(68.8889, device='cuda:0')\n",
      "tensor(68.5000, device='cuda:0')\n",
      "tensor(69.0909, device='cuda:0')\n",
      "tensor(67.5000, device='cuda:0')\n",
      "tensor(67.3077, device='cuda:0')\n",
      "tensor(67.8571, device='cuda:0')\n",
      "tensor(69.3333, device='cuda:0')\n",
      "tensor(68.4375, device='cuda:0')\n",
      "tensor(68.2353, device='cuda:0')\n",
      "tensor(68.0556, device='cuda:0')\n",
      "tensor(69.2105, device='cuda:0')\n",
      "tensor(69.5000, device='cuda:0')\n",
      "tensor(69.2857, device='cuda:0')\n",
      "tensor(70.2273, device='cuda:0')\n",
      "tensor(71.3043, device='cuda:0')\n",
      "tensor(71.4583, device='cuda:0')\n",
      "tensor(71.4000, device='cuda:0')\n",
      "tensor(71.5385, device='cuda:0')\n",
      "tensor(71.6667, device='cuda:0')\n",
      "tensor(71.7857, device='cuda:0')\n",
      "tensor(71.0345, device='cuda:0')\n",
      "tensor(71., device='cuda:0')\n",
      "tensor(70.6452, device='cuda:0')\n",
      "tensor(70.6250, device='cuda:0')\n",
      "tensor(70.4545, device='cuda:0')\n",
      "tensor(70.2941, device='cuda:0')\n",
      "tensor(70.4286, device='cuda:0')\n",
      "tensor(70.4167, device='cuda:0')\n",
      "tensor(70.4054, device='cuda:0')\n",
      "tensor(70.5263, device='cuda:0')\n",
      "tensor(70.5128, device='cuda:0')\n",
      "tensor(70.1250, device='cuda:0')\n",
      "tensor(69.8781, device='cuda:0')\n",
      "tensor(69.5238, device='cuda:0')\n",
      "tensor(69.0698, device='cuda:0')\n",
      "tensor(68.7500, device='cuda:0')\n",
      "tensor(68.8889, device='cuda:0')\n",
      "tensor(68.5870, device='cuda:0')\n",
      "tensor(68.5106, device='cuda:0')\n",
      "tensor(68.3333, device='cuda:0')\n",
      "tensor(68.4694, device='cuda:0')\n",
      "tensor(68.3000, device='cuda:0')\n",
      "tensor(68.3333, device='cuda:0')\n",
      "tensor(68.3654, device='cuda:0')\n",
      "tensor(68.3962, device='cuda:0')\n",
      "tensor(68.4259, device='cuda:0')\n",
      "tensor(68.3636, device='cuda:0')\n",
      "tensor(68.6607, device='cuda:0')\n",
      "tensor(68.3333, device='cuda:0')\n",
      "tensor(68.2759, device='cuda:0')\n",
      "tensor(68.1356, device='cuda:0')\n",
      "tensor(68.2500, device='cuda:0')\n",
      "tensor(68.5246, device='cuda:0')\n",
      "tensor(68.6290, device='cuda:0')\n",
      "tensor(68.8889, device='cuda:0')\n",
      "tensor(69.0625, device='cuda:0')\n",
      "tensor(69.1538, device='cuda:0')\n",
      "tensor(69.0909, device='cuda:0')\n",
      "tensor(69.0299, device='cuda:0')\n",
      "tensor(68.8971, device='cuda:0')\n",
      "tensor(69.1304, device='cuda:0')\n",
      "tensor(69.2143, device='cuda:0')\n",
      "tensor(69.4366, device='cuda:0')\n",
      "tensor(69.4444, device='cuda:0')\n",
      "tensor(69.6575, device='cuda:0')\n",
      "tensor(69.7973, device='cuda:0')\n",
      "tensor(69.7333, device='cuda:0')\n",
      "tensor(69.8684, device='cuda:0')\n",
      "tensor(69.8701, device='cuda:0')\n",
      "tensor(70.0641, device='cuda:0')\n",
      "tensor(69.9367, device='cuda:0')\n",
      "tensor(69.6875, device='cuda:0')\n",
      "tensor(69.8148, device='cuda:0')\n",
      "tensor(69.6951, device='cuda:0')\n",
      "tensor(69.8193, device='cuda:0')\n",
      "tensor(69.8810, device='cuda:0')\n",
      "tensor(70.1176, device='cuda:0')\n",
      "tensor(70.2326, device='cuda:0')\n",
      "tensor(70.2874, device='cuda:0')\n",
      "tensor(70.2841, device='cuda:0')\n",
      "tensor(70.3933, device='cuda:0')\n",
      "tensor(70.3333, device='cuda:0')\n",
      "tensor(70.3297, device='cuda:0')\n",
      "tensor(70.3261, device='cuda:0')\n",
      "tensor(70.3763, device='cuda:0')\n",
      "tensor(70.4255, device='cuda:0')\n",
      "tensor(70.3684, device='cuda:0')\n",
      "tensor(70.3125, device='cuda:0')\n",
      "tensor(70.0516, device='cuda:0')\n",
      "tensor(69.8469, device='cuda:0')\n",
      "tensor(69.7980, device='cuda:0')\n",
      "tensor(69.6500, device='cuda:0')\n",
      "tensor(69.6535, device='cuda:0')\n",
      "tensor(69.7549, device='cuda:0')\n",
      "tensor(69.7573, device='cuda:0')\n",
      "tensor(69.8077, device='cuda:0')\n",
      "tensor(69.7143, device='cuda:0')\n",
      "tensor(69.5283, device='cuda:0')\n",
      "tensor(69.6262, device='cuda:0')\n",
      "tensor(69.6759, device='cuda:0')\n",
      "tensor(69.8165, device='cuda:0')\n",
      "tensor(69.9091, device='cuda:0')\n",
      "tensor(69.9550, device='cuda:0')\n",
      "tensor(69.9107, device='cuda:0')\n",
      "tensor(69.8673, device='cuda:0')\n",
      "tensor(69.8246, device='cuda:0')\n",
      "tensor(69.8261, device='cuda:0')\n",
      "tensor(69.8707, device='cuda:0')\n",
      "tensor(69.9145, device='cuda:0')\n",
      "tensor(69.9576, device='cuda:0')\n",
      "tensor(69.9580, device='cuda:0')\n",
      "tensor(69.9167, device='cuda:0')\n",
      "tensor(69.8347, device='cuda:0')\n",
      "tensor(69.8771, device='cuda:0')\n",
      "tensor(69.7561, device='cuda:0')\n",
      "tensor(69.8387, device='cuda:0')\n",
      "tensor(69.8400, device='cuda:0')\n",
      "tensor(69.8810, device='cuda:0')\n",
      "tensor(69.9606, device='cuda:0')\n",
      "tensor(69.9219, device='cuda:0')\n",
      "tensor(70., device='cuda:0')\n",
      "tensor(69.9615, device='cuda:0')\n",
      "tensor(69.9618, device='cuda:0')\n",
      "tensor(69.9242, device='cuda:0')\n",
      "tensor(69.9624, device='cuda:0')\n",
      "tensor(70., device='cuda:0')\n",
      "tensor(70., device='cuda:0')\n",
      "tensor(69.8897, device='cuda:0')\n",
      "tensor(69.9270, device='cuda:0')\n",
      "tensor(69.9275, device='cuda:0')\n",
      "tensor(69.8561, device='cuda:0')\n",
      "tensor(69.7857, device='cuda:0')\n",
      "tensor(69.6454, device='cuda:0')\n",
      "tensor(69.6479, device='cuda:0')\n",
      "tensor(69.5455, device='cuda:0')\n",
      "tensor(69.5486, device='cuda:0')\n",
      "tensor(69.5172, device='cuda:0')\n",
      "tensor(69.4178, device='cuda:0')\n",
      "tensor(69.2517, device='cuda:0')\n",
      "tensor(69.1554, device='cuda:0')\n",
      "tensor(69.0268, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "\r",
      "  0%|          | 1/1500 [17:13<430:08:16, 1033.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(68.9667, device='cuda:0')\n",
      "tensor(68.8742, device='cuda:0')\n",
      "tensor(68.7500, device='cuda:0')\n",
      "tensor(68.7909, device='cuda:0')\n",
      "tensor(68.7987, device='cuda:0')\n",
      "tensor(68.8387, device='cuda:0')\n",
      "tensor(68.8782, device='cuda:0')\n",
      "tensor(68.7898, device='cuda:0')\n",
      "tensor(68.7342, device='cuda:0')\n",
      "tensor(68.7107, device='cuda:0')\n",
      "tensor(68.6250, device='cuda:0')\n",
      "tensor(68.5714, device='cuda:0')\n",
      "tensor(68.5803, device='cuda:0')\n",
      "tensor(68.3742, device='cuda:0')\n",
      "tensor(68.2622, device='cuda:0')\n",
      "tensor(68.3333, device='cuda:0')\n",
      "tensor(68.2831, device='cuda:0')\n",
      "tensor(68.2635, device='cuda:0')\n",
      "tensor(68.2440, device='cuda:0')\n",
      "tensor(68.1361, device='cuda:0')\n",
      "tensor(68.1176, device='cuda:0')\n",
      "tensor(67.9825, device='cuda:0')\n",
      "tensor(67.8488, device='cuda:0')\n",
      "tensor(67.8035, device='cuda:0')\n",
      "tensor(67.8161, device='cuda:0')\n",
      "tensor(67.7714, device='cuda:0')\n",
      "tensor(67.7273, device='cuda:0')\n",
      "tensor(67.6836, device='cuda:0')\n",
      "tensor(67.6124, device='cuda:0')\n",
      "tensor(67.6536, device='cuda:0')\n",
      "tensor(67.6944, device='cuda:0')\n",
      "tensor(67.5967, device='cuda:0')\n",
      "tensor(67.5000, device='cuda:0')\n",
      "tensor(67.5683, device='cuda:0')\n",
      "tensor(67.4728, device='cuda:0')\n",
      "tensor(67.5405, device='cuda:0')\n",
      "tensor(67.5269, device='cuda:0')\n",
      "tensor(67.4599, device='cuda:0')\n",
      "tensor(67.3670, device='cuda:0')\n",
      "tensor(67.3280, device='cuda:0')\n",
      "tensor(67.3158, device='cuda:0')\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 3619 is out of bounds for axis 0 with size 3619",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-fbaf480bc3b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_loc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mexample_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../brainhack/Sub-\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".nii.gz\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 3619 is out of bounds for axis 0 with size 3619"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "    \n",
    "df = np.genfromtxt(\"preprocessing/encoded_track2_labels_v2.csv\",delimiter=',')\n",
    "x_loc = df[1:,0]\n",
    "y_loc = df[1:,1]\n",
    "\n",
    "\n",
    "\n",
    "#df = np.genfromtxt(\"preprocessing/encoded_track2_labels.csv\",delimiter=',')\n",
    "#x_loc = df[1:,2]\n",
    "#y_loc = df[1:,3]\n",
    "\n",
    "\n",
    "epochs = 1500\n",
    "# in your training loop:\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    offset = 0\n",
    "    for i in range(150):\n",
    "        for j in range(batch_size):\n",
    "            loc = x_loc[j+offset]\n",
    "            example_filename = \"../brainhack/Sub-\" + str(int(loc)) + \".nii.gz\"\n",
    "            img = nib.load(example_filename)\n",
    "            data = img.get_fdata()\n",
    "            x[j,0,:,:,:] = torch.from_numpy(data).float()\n",
    "            y[j] = y_loc[j+offset]\n",
    "        offset = j+offset\n",
    "        input = x/x.max()\n",
    "        \n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()   # zero the gradient buffers\n",
    "        input = input.cuda()\n",
    "        y = y.cuda()\n",
    "        output = net(input)\n",
    "        loss = criterion(output.view(batch_size), y.view(batch_size))\n",
    "        loss.backward()\n",
    "        optimizer.step()    # Does the update\n",
    "        correct += ((output > 0.5).view(-1)*(y>0.5).view(-1)).sum()\n",
    "        total += batch_size\n",
    "        print(correct.float()*100/total)\n",
    "    \n",
    "    # save model\n",
    "    if epoch % 10 == 0:\n",
    "        torch.save(net,'cnn_epoch_'+str(epoch)+'.pt')\n",
    "#         print(loss)\n",
    "#         print(output)\n",
    "#         print(y)\n",
    "#         print(input.sum())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded!\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "\n",
    "net = torch.load('cnn_epoch_10.pt')\n",
    "net.eval()\n",
    "print('Model loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1489 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "tensor(60., device='cuda:0')\n",
      "[tensor([[0.6436, 0.6422, 0.6452, 0.6446, 0.6452, 0.6467, 0.6491, 0.6419, 0.6477,\n",
      "         0.6426, 0.6422, 0.6502, 0.6423, 0.6434, 0.6422, 0.6473, 0.6494, 0.6423,\n",
      "         0.6467, 0.6422]], device='cuda:0', grad_fn=<PermuteBackward>), tensor([0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,\n",
      "        0., 1.], device='cuda:0')]\n",
      "tensor(52.5000, device='cuda:0')\n",
      "[tensor([[0.6416, 0.6416, 0.6416, 0.6416, 0.6416, 0.6416, 0.6501, 0.6416, 0.6416,\n",
      "         0.6416, 0.6416, 0.6416, 0.6416, 0.6416, 0.6416, 0.6416, 0.6416, 0.6416,\n",
      "         0.6416, 0.6416]], device='cuda:0', grad_fn=<PermuteBackward>), tensor([1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0.,\n",
      "        1., 1.], device='cuda:0')]\n",
      "tensor(50.0000, device='cuda:0')\n",
      "[tensor([[0.6442, 0.6417, 0.6417, 0.6440, 0.6417, 0.6439, 0.6419, 0.6422, 0.6418,\n",
      "         0.6459, 0.6426, 0.6420, 0.6417, 0.6420, 0.6419, 0.6424, 0.6418, 0.6418,\n",
      "         0.6417, 0.6416]], device='cuda:0', grad_fn=<PermuteBackward>), tensor([1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
      "        1., 1.], device='cuda:0')]\n",
      "tensor(56.2500, device='cuda:0')\n",
      "[tensor([[0.6418, 0.6476, 0.6447, 0.6423, 0.6487, 0.6430, 0.6434, 0.6425, 0.6429,\n",
      "         0.6437, 0.6422, 0.6424, 0.6423, 0.6437, 0.6436, 0.6421, 0.6421, 0.6424,\n",
      "         0.6424, 0.6418]], device='cuda:0', grad_fn=<PermuteBackward>), tensor([1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
      "        0., 0.], device='cuda:0')]\n",
      "tensor(56., device='cuda:0')\n",
      "[tensor([[0.6416, 0.6416, 0.6416, 0.6416, 0.6416, 0.6416, 0.6416, 0.6416, 0.6417,\n",
      "         0.6416, 0.6475, 0.6416, 0.6416, 0.6416, 0.6416, 0.6416, 0.6416, 0.6416,\n",
      "         0.6416, 0.6416]], device='cuda:0', grad_fn=<PermuteBackward>), tensor([0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0.,\n",
      "        1., 1.], device='cuda:0')]\n",
      "tensor(54.1667, device='cuda:0')\n",
      "[tensor([[0.6416, 0.6416, 0.6416, 0.6416, 0.6416, 0.6416, 0.6416, 0.6416, 0.6480,\n",
      "         0.6416, 0.6416, 0.6416, 0.6416, 0.6416, 0.6416, 0.6416, 0.6416, 0.6416,\n",
      "         0.6416, 0.6416]], device='cuda:0', grad_fn=<PermuteBackward>), tensor([1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0.,\n",
      "        1., 0.], device='cuda:0')]\n",
      "tensor(51.4286, device='cuda:0')\n",
      "[tensor([[0.6416, 0.6416, 0.6416, 0.6416, 0.6484, 0.6416, 0.6482, 0.6416, 0.6416,\n",
      "         0.6416, 0.6416, 0.6416, 0.6416, 0.6416, 0.6416, 0.6416, 0.6416, 0.6416,\n",
      "         0.6416, 0.6416]], device='cuda:0', grad_fn=<PermuteBackward>), tensor([0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "        1., 1.], device='cuda:0')]\n",
      "tensor(51.2500, device='cuda:0')\n",
      "[tensor([[0.6419, 0.6421, 0.6450, 0.6481, 0.6424, 0.6423, 0.6492, 0.6484, 0.6451,\n",
      "         0.6520, 0.6440, 0.6424, 0.6483, 0.6476, 0.6436, 0.6424, 0.6418, 0.6503,\n",
      "         0.6425, 0.6438]], device='cuda:0', grad_fn=<PermuteBackward>), tensor([1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1.,\n",
      "        0., 1.], device='cuda:0')]\n",
      "tensor(47.7778, device='cuda:0')\n",
      "[tensor([[0.6416, 0.6416, 0.6416, 0.6416, 0.6416, 0.6416, 0.6416, 0.6417, 0.6416,\n",
      "         0.6416, 0.6416, 0.6468, 0.6417, 0.6416, 0.6416, 0.6416, 0.6417, 0.6416,\n",
      "         0.6417, 0.6416]], device='cuda:0', grad_fn=<PermuteBackward>), tensor([1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0.,\n",
      "        1., 1.], device='cuda:0')]\n",
      "tensor(47.5000, device='cuda:0')\n",
      "[tensor([[0.6416, 0.6416, 0.6416, 0.6416, 0.6416, 0.6416, 0.6416, 0.6416, 0.6416,\n",
      "         0.6416, 0.6416, 0.6416, 0.6416, 0.6416, 0.6416, 0.6416, 0.6472, 0.6416,\n",
      "         0.6416, 0.6416]], device='cuda:0', grad_fn=<PermuteBackward>), tensor([1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0.,\n",
      "        1., 0.], device='cuda:0')]\n",
      "tensor(48.6364, device='cuda:0')\n",
      "[tensor([[0.6419, 0.6429, 0.6454, 0.6420, 0.6426, 0.6429, 0.6416, 0.6459, 0.6447,\n",
      "         0.6427, 0.6461, 0.6416, 0.6431, 0.6423, 0.6418, 0.6420, 0.6459, 0.6458,\n",
      "         0.6429, 0.6432]], device='cuda:0', grad_fn=<PermuteBackward>), tensor([0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1.,\n",
      "        0., 1.], device='cuda:0')]\n",
      "tensor(49.5833, device='cuda:0')\n",
      "[tensor([[0.6440, 0.6469, 0.6428, 0.6419, 0.6422, 0.6437, 0.6503, 0.6430, 0.6440,\n",
      "         0.6421, 0.6424, 0.6432, 0.6464, 0.6439, 0.6475, 0.6490, 0.6436, 0.6422,\n",
      "         0.6485, 0.6448]], device='cuda:0', grad_fn=<PermuteBackward>), tensor([1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
      "        1., 0.], device='cuda:0')]\n",
      "tensor(50.7692, device='cuda:0')\n",
      "[tensor([[0.6416, 0.6416, 0.6416, 0.6416, 0.6416, 0.6446, 0.6416, 0.6416, 0.6456,\n",
      "         0.6416, 0.6416, 0.6416, 0.6416, 0.6416, 0.6416, 0.6416, 0.6416, 0.6416,\n",
      "         0.6416, 0.6416]], device='cuda:0', grad_fn=<PermuteBackward>), tensor([0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 0.], device='cuda:0')]\n",
      "tensor(50., device='cuda:0')\n",
      "[tensor([[0.6426, 0.6422, 0.6422, 0.6450, 0.6420, 0.6499, 0.6435, 0.6437, 0.6422,\n",
      "         0.6424, 0.6446, 0.6424, 0.6430, 0.6431, 0.6439, 0.6425, 0.6423, 0.6440,\n",
      "         0.6423, 0.6421]], device='cuda:0', grad_fn=<PermuteBackward>), tensor([0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1.], device='cuda:0')]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-d057983698c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mexample_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../brainhack/Sub-\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".nii.gz\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_fdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_loc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/nibabel/dataobj_images.py\u001b[0m in \u001b[0;36mget_fdata\u001b[0;34m(self, caching, dtype)\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fdata_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fdata_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcaching\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'fill'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fdata_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masanyarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \"\"\"\n\u001b[0;32m--> 553\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/nibabel/arrayproxy.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;31m# Read array and scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0mraw_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_unscaled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mapply_read_scaling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/nibabel/arrayproxy.py\u001b[0m in \u001b[0;36mget_unscaled\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    348\u001b[0m                                        \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_offset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m                                        \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m                                        mmap=self._mmap)\n\u001b[0m\u001b[1;32m    351\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/nibabel/volumeutils.py\u001b[0m in \u001b[0;36marray_from_file\u001b[0;34m(shape, in_dtype, infile, offset, order, mmap)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0minfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'readinto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m         \u001b[0mdata_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m         \u001b[0mn_read\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0mneeds_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "\n",
    "epochs = 1500\n",
    "# in your training loop:\n",
    "for epoch in tqdm(range(11, epochs)):\n",
    "    print(epoch)\n",
    "    offset = 3000\n",
    "    for i in range(30):\n",
    "        for j in range(batch_size):\n",
    "            loc = x_loc[j+offset]\n",
    "            example_filename = \"../brainhack/Sub-\" + str(int(loc)) + \".nii.gz\"\n",
    "            img = nib.load(example_filename)\n",
    "            data = img.get_fdata()\n",
    "            x[j,0,:,:,:] = torch.from_numpy(data).float()\n",
    "            y[j] = y_loc[j+offset]\n",
    "        offset = j+offset\n",
    "        input = x/x.max()\n",
    "        \n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()   # zero the gradient buffers\n",
    "        input = input.cuda()\n",
    "        y = y.cuda()\n",
    "        output = net(input)\n",
    "        loss = criterion(output.view(batch_size), y.view(batch_size))\n",
    "        loss.backward()\n",
    "        optimizer.step()    # Does the update\n",
    "        correct += ((output > 0.642).view(-1)*(y>0.5).view(-1)).sum()\n",
    "        correct += ((output < 0.642).view(-1)*(y<0.5).view(-1)).sum()\n",
    "        total += batch_size\n",
    "        print(correct.float()*100/total)\n",
    "        print([output.T, y])\n",
    "    \n",
    "    # save model\n",
    "#     if epoch % 10 == 0:\n",
    "#         torch.save(net,'cnn_epoch_'+str(epoch)+'.pt')\n",
    "    torch.save(net,'cnn_epoch_'+str(epoch)+'.pt')\n",
    "#         print(loss)\n",
    "#         print(output)\n",
    "#         print(y)\n",
    "#         print(input.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "\n",
    "epochs = 10\n",
    "# in your training loop:\n",
    "for epoch in tqdm(range(11, epochs)):\n",
    "    print(epoch)\n",
    "    offset = 0\n",
    "    for i in range(150):\n",
    "        for j in range(batch_size):\n",
    "            loc = x_loc[j+offset]\n",
    "            example_filename = \"../brainhack/Sub-\" + str(int(loc)) + \".nii.gz\"\n",
    "            img = nib.load(example_filename)\n",
    "            data = img.get_fdata()\n",
    "            x[j,0,:,:,:] = torch.from_numpy(data).float()\n",
    "            y[j] = y_loc[j+offset]\n",
    "        offset = j+offset\n",
    "        input = x/x.max()\n",
    "        \n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()   # zero the gradient buffers\n",
    "        input = input.cuda()\n",
    "        y = y.cuda()\n",
    "        output = net(input)\n",
    "        loss = criterion(output.view(batch_size), y.view(batch_size))\n",
    "        loss.backward()\n",
    "        optimizer.step()    # Does the update\n",
    "        correct += ((output > 0.5).view(-1)*(y>0.5).view(-1)).sum()\n",
    "        total += batch_size\n",
    "        print(correct.float()*100/total)\n",
    "    \n",
    "    # save model\n",
    "#     if epoch % 10 == 0:\n",
    "#         torch.save(net,'cnn_epoch_'+str(epoch)+'.pt')\n",
    "    torch.save(net,'cnn_epoch_'+str(epoch)+'.pt')\n",
    "#         print(loss)\n",
    "#         print(output)\n",
    "#         print(y)\n",
    "#         print(input.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13, device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " ((output > 0.5).view(-1)*(y>0.5).view(-1)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo -H pip3 install nibabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
